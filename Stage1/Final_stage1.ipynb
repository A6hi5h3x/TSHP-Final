{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "bDtjmA3hCKKg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics.pairwise import pairwise_distances, euclidean_distances\n",
        "from sklearn.cluster import KMeans\n",
        "import sklearn.metrics as metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "import configparser\n",
        "import os.path as path\n",
        "\n",
        "config = configparser.ConfigParser()\n",
        "config.read('./metadata.cfg')\n",
        "\n",
        "sections= config.sections()\n",
        "data= config[sections[0]]\n",
        "clustering= config[sections[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets= {}\n",
        "datasets[1]= 'dermatology'\n",
        "datasets[2]= 'glass'\n",
        "datasets[3]= 'haberman'\n",
        "datasets[4]= 'ionosphere'\n",
        "datasets[5]= 'iris'\n",
        "datasets[6]= 'parkinsons'\n",
        "datasets[7]= 'pendigit'\n",
        "datasets[8]= 'seeds'\n",
        "datasets[9]= 'vehiclesilhouettes'\n",
        "datasets[10]= 'wine'\n",
        "datasets[11]= 'rice1'\n",
        "datasets[12]= 'rice2'\n",
        "datasets[13]= 'rice3'\n",
        "datasets[14]= 'rice4'\n",
        "datasets[15]= 'ant1.7'\n",
        "datasets[16]= 'zuzel'\n",
        "datasets[17]= 'cm1'\n",
        "datasets[18]= 'kc1'\n",
        "datasets[19]= 'kc2'\n",
        "datasets[20]= 'pc1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "datadir= data['datadir']\n",
        "dataset= int(data['dataset'])\n",
        "\n",
        "filepath= path.join(datadir, data[str(dataset)]+'.csv')\n",
        "labelfilepath= path.join(datadir, data[str(dataset)]+'_labels.csv')\n",
        "normalize= data['normalize']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "datasets\\pc1.csv\n"
          ]
        }
      ],
      "source": [
        "print(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "McdwUe96DG-J"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(filepath, header=None, index_col=False)\n",
        "data_labels= pd.read_csv(labelfilepath, header=None, index_col=False).T.iloc[0].to_numpy()\n",
        "\n",
        "actual_data= data.copy().to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "if normalize=='MMN':\n",
        "    data = pd.DataFrame(MinMaxScaler().fit_transform(data))\n",
        "else:\n",
        "    raise TypeError(normalize, \" is not correct\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "data= data.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_val= np.min(data)\n",
        "if min_val >0:\n",
        "    eps = np.e\n",
        "else:\n",
        "    eps = abs(min_val)+(np.e)\n",
        "   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "def euclidean_distance(x, y):\n",
        "    return np.sqrt(np.sum((x-y)**2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eucli\n",
            "S\n"
          ]
        }
      ],
      "source": [
        "euclidean_distances= pairwise_distances(data, metric='euclidean')\n",
        "print('Eucli')\n",
        "s_distances= pairwise_distances(data, metric=s_distance)\n",
        "print('S')\n",
        "w1= 0.5\n",
        "distances= np.sqrt(w1*(euclidean_distances**2)+ (1-w1)*(s_distances**2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_clusters(dataset, labels, centroids, title):\n",
        "    pca = PCA(n_components=2)\n",
        "    data_2d = pca.fit_transform(dataset)\n",
        "    if len(centroids)>0:\n",
        "        centroids_2d = pca.transform(centroids)\n",
        "    clear_output(wait=True)\n",
        "    plt.title(title)\n",
        "    plt.scatter(x=data_2d[:,0], y=data_2d[:,1], c=labels)\n",
        "    if len(centroids)>0:\n",
        "        plt.scatter(x=centroids_2d[:,0], y=centroids_2d[:,1])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "2XXC5asZcZuk"
      },
      "outputs": [],
      "source": [
        "def density(ind, threshold, distances):\n",
        "    \n",
        "    samples_array= np.where(distances[ind]< threshold)[0].tolist()\n",
        "    dens= len(samples_array)\n",
        "\n",
        "    return dens, samples_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "lMGFLH_0Kn_c"
      },
      "outputs": [],
      "source": [
        "def avg_cluster_distance(samples_array, p_i, p, distances):\n",
        "    if p_i<2:\n",
        "        return 0 \n",
        "    fil_dists= distances[samples_array][:,samples_array]\n",
        "    tdis = np.triu(fil_dists, k=0).sum()\n",
        "\n",
        "    return 2*tdis/(p_i*(p_i-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loop_density_canopy(data, distances):\n",
        "    remain= np.arange(0, n)\n",
        "\n",
        "    mdis= mean_dis(distances)\n",
        "    print(\"Mean Distance: \",mdis)\n",
        "    cluster_centers= np.array([], dtype=int)\n",
        "    clusters= []\n",
        "    mdists= np.array([])\n",
        "\n",
        "    \n",
        "    p= np.array([])\n",
        "    samples_arrays= []\n",
        "    for i in range(n):\n",
        "        p_i, samples_array= density(i, mdis, distances)\n",
        "        samples_arrays.append(samples_array)\n",
        "        p= np.append(p, p_i)\n",
        "\n",
        "    max_p= max(p)\n",
        "    max_ps= np.where(p==max_p)[0]\n",
        "    a= np.array([])\n",
        "    for i in max_ps:\n",
        "        a_i= avg_cluster_distance(samples_arrays[i], p[i], p, distances)\n",
        "        a= np.append(a, a_i)\n",
        "    min_a= np.argmin(a[np.arange((len(max_ps)))])\n",
        "    ind= max_ps[min_a]\n",
        "    cluster_centers= np.append(cluster_centers, remain[ind])\n",
        "    _, cluster_samples= density(ind, mdis, distances)\n",
        "    clusters.append(remain[cluster_samples])\n",
        "    remain= np.delete(remain, cluster_samples)\n",
        "    mdists= np.append(mdists, mdis)\n",
        "\n",
        "    cluster_idx= 1\n",
        "    print(\"No.of remaining elements: \", len(remain))\n",
        "    print('\\n')\n",
        "\n",
        "    \n",
        "    while len(remain)>0:\n",
        "\n",
        "        dists= distances[:,remain][remain]\n",
        "\n",
        "        print(\"Mean Distance: \", mdis)\n",
        "\n",
        "        r= len(remain)\n",
        "        p= np.zeros((r))\n",
        "        a= np.zeros((r))\n",
        "        s= np.zeros((r))\n",
        "        w= np.zeros((r))\n",
        "        for i in range(r):\n",
        "            p_i, samples_array= density(i, mdis, dists)\n",
        "            a_i= avg_cluster_distance(samples_array, p_i, p, dists)\n",
        "            p[i]= p_i\n",
        "            a[i]= a_i\n",
        "        \n",
        "        for i in range(r):\n",
        "            s_i= cluster_distance(i, p[i], p, dists)\n",
        "            s[i]= s_i\n",
        "            w[i]= weight_product(p[i], a[i], s_i)\n",
        "        \n",
        "\n",
        "        max_w= max(w)\n",
        "        \n",
        "        min_p= 0.03*n  \n",
        "        print(\"Maximum Density: \",max(p))\n",
        "        removed= np.array([], dtype=int)\n",
        "        if max_w==0 or max(p)<min_p:\n",
        "            print(\"No.of elements remaining: \", len(remain))\n",
        "            print(p)\n",
        "            for i in remain:    \n",
        "                cen_dists= distances[:,cluster_centers][i]\n",
        "                min_cen= np.argmin(cen_dists) \n",
        "                if(cen_dists[min_cen]< 1.5*mdists[min_cen]):\n",
        "                    clusters[min_cen]= np.append(clusters[min_cen], i)\n",
        "                else:\n",
        "                    removed= np.append(removed, i)\n",
        "            break\n",
        "        \n",
        "        max_ws= np.where(w==max_w)[0]\n",
        "        min_a= np.argmin(a[max_ws])\n",
        "        ind= max_ws[min_a]\n",
        "        cluster_centers= np.append(cluster_centers, remain[ind])\n",
        "        _, cluster_samples= density(ind, mdis, dists)\n",
        "        clusters.append(remain[cluster_samples])\n",
        "        remain= np.delete(remain, cluster_samples)\n",
        "        mdists= np.append(mdists, mdis)\n",
        "\n",
        "        cluster_idx+= 1\n",
        "        print(\"No.of elements remaining: \", len(remain))\n",
        "        print('\\n')\n",
        "    \n",
        "    return cluster_centers, clusters, removed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "init_labels= -1*np.ones(n).astype(np.int64)\n",
        "incl= np.delete(np.arange(n), removed)\n",
        "incl_labels= np.argmin(distances[:,cluster_centers][incl], axis=1)\n",
        "init_centroids= np.empty((k, m))\n",
        "for i in range(k):\n",
        "    cent= np.mean(data[incl][np.where(incl_labels==i)[0]], axis=0)\n",
        "    init_centroids[i]= cent\n",
        "\n",
        "for i in range(len(incl)):\n",
        "    init_labels[incl[i]]= incl_labels[i]\n",
        "\n",
        "cl=0\n",
        "for i in range(k):\n",
        "    init_centroids[cl]= np.mean(data[np.where(init_labels==i)[0]], axis=0)\n",
        "    cl+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [],
      "source": [
        "def new_centers(data, labels, k):\n",
        "    centers = data.groupby(labels).mean() \n",
        "    return centers.values   \n",
        "\n",
        "def get_labels_with_hybrid_distance(dataset, cluster_centers, wc, we):\n",
        "    hybrid_distances = np.zeros((len(dataset), len(cluster_centers)))\n",
        "\n",
        "    \n",
        "    for i, data_point in enumerate(dataset):\n",
        "        for j, center in enumerate(cluster_centers):\n",
        "            hybrid_distances[i, j] = hybrid_distance(data_point, center, wc, we)\n",
        "\n",
        "    \n",
        "    return np.argmin(hybrid_distances, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No.of clusters formed :  2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for i in removed:\n",
        "    cen_dists= np.array([])\n",
        "    for j in centers:\n",
        "        cen_dists= np.append(cen_dists, hybrid_distance(data[i], j, w1, 1-w1))\n",
        "    labels= np.insert(labels, i, np.argmin(cen_dists))\n",
        "_,counts= np.unique(labels, return_counts=True)\n",
        "\n",
        "print(\"No.of clusters formed : \",len(counts))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "envjup",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
